{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import os\n",
    "from glob import glob\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from fastai import fastai\n",
    "from fastai.fastai import transforms\n",
    "from fastai.fastai import conv_learner\n",
    "from fastai.fastai import model\n",
    "from fastai.fastai import dataset\n",
    "from fastai.fastai import sgdr\n",
    "from fastai.fastai import plots as faplots\n",
    "from fastai.fastai import metrics\n",
    "from fastai.fastai import structured\n",
    "from fastai.fastai import column_data\n",
    "from torchvision.models import resnet18, resnet34\n",
    "from fastai.fastai.torch_imports import resnext101_64\n",
    "import torch\n",
    "import dill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00:00:24 - Fast.AI student article recap\n",
    "\n",
    "* [Improving the way we work with learning rate](https://techburst.io/improving-the-way-we-work-with-learning-rate-5e99554f163b?gi=79e0118def63)\n",
    "* [The Cyclical Learning Rate technique](http://teleported.in/posts/cyclic-learning-rate/)\n",
    "* [Exploring Stochastic Gradient Descent with Restarts (SGDR)](https://medium.com/38th-street-studios/exploring-stochastic-gradient-descent-with-restarts-sgdr-fa206c38a74e)\n",
    "* [Transfer Learning using differential learning rates](https://towardsdatascience.com/transfer-learning-using-differential-learning-rates-638455797f00)\n",
    "* [Getting Computers To See Better Than Humans](https://medium.com/@ArjunRajkumar/getting-computers-to-see-better-than-humans-346d96634f73)\n",
    "\n",
    "## 00:03:30 - Lessons recap and plan\n",
    "\n",
    "* Lesson 1, 2 and 3 = CNN image intro\n",
    "* Lesson 4 = Structured data, language RNN and collaborative filtering.\n",
    "* Lesson 5 = SGD and loss function + collaborative filtering in depth.\n",
    "\n",
    "## 00:04:59 - Dropout\n",
    "\n",
    "* Activation is just a number, calculated using some parameters.\n",
    "* Firstly, examine the precomputed `ConvLearner` object below, which only includes the last, fully-connected, layers of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/dogbreed/'\n",
    "arch = resnet34\n",
    "sz = 224\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfms = transforms.tfms_from_model(arch, sz, aug_tfms=transforms.transforms_side_on, max_zoom=1.1)\n",
    "data = dataset.ImageClassifierData.from_csv(\n",
    "    PATH, 'train', f'{PATH}labels.csv',\n",
    "    test_name='test', suffix='.jpg', tfms=tfms, bs=bs)\n",
    "learn = conv_learner.ConvLearner.pretrained(arch, data, ps=0.5, precompute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (1): Dropout(p=0.5)\n",
       "  (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (5): Dropout(p=0.5)\n",
       "  (6): Linear(in_features=512, out_features=120, bias=True)\n",
       "  (7): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note the following layers:\n",
    "  * `BatchNorm1d` - covered in the last lesson.\n",
    "  * `Linear` - matrix multiplier.\n",
    "    * A matrix which is size `(1024, 512)`.\n",
    "    * Takes in `1024` activations and returns `512` activations.\n",
    "  * `ReLU` - replaces negatives with 0.\n",
    "  * `LogSoftmax` - put the previous linear layers activations and return log probability.\n",
    "  \n",
    "* `Dropout` with p=0.5, simply means: delete 50% of the activations at random:\n",
    "\n",
    "<img src=\"https://i.gyazo.com/d8d5cd5d62faca8eb70554502dc8f189.gif\" width=\"400px\">\n",
    "\n",
    "* Forces the model not to overfit:\n",
    "  * If one activation has learned about an \"exact\" dog breed, then when it's removed, it's going to hurt the loss.\n",
    "  * Model has to find a fit that works, even without certain activations.\n",
    "\n",
    "* Critical in making modern deep learning work.\n",
    "  * Solved the problem of generalisation.\n",
    "  \n",
    "### 00:13:24 - Audience questions\n",
    "\n",
    "* Question 1: Do you have to do anything to accomodate for the fact you're throwing away activations?\n",
    "* Answer 1: All handled behind the scenes by PyTorch. If you set `p=0.5`, PyTorch will double the number of activations to account for the deleted ones.\n",
    "\n",
    "***\n",
    "\n",
    "* For minor precision reasons, we take the log of the softmax on the final layer, which means we need to convert it with `exp`.\n",
    "* You can pass in `ps=0.5` to change the Dropout on the added layers, not on the pretrained layers.\n",
    "* Setting `ps=0` will remove Dropout all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (4): Linear(in_features=512, out_features=120, bias=True)\n",
       "  (5): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_learner.ConvLearner.pretrained(arch, data, ps=0, precompute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can also pass `xtra_fc=[<list of extra FC layers>]` as a list of additional fully-connected layers. Empty list would exclude all but the final layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (1): Linear(in_features=1024, out_features=120, bias=True)\n",
       "  (2): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_learner.ConvLearner.pretrained(arch, data, ps=0, precompute=True, xtra_fc=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00:17:54 - Audience questions\n",
    "\n",
    "* Question 1: What sort of `p` should we use by default?\n",
    "* Answer 1: Fast.ai defaults to `.25` for 2nd layer and `0.5` for last layer - works well for most things.\n",
    "  * Bump it up if overfitting.\n",
    "  * Lower if underfitting.\n",
    "  * Bigger models will generally need more dropout.\n",
    "  \n",
    "* Question 2: Setting `p=0.5` is that 50%?\n",
    "* Answer 2: Yes.\n",
    "\n",
    "* Question 3: How can you determine if you're overfitting?\n",
    "* Answer 3: Yes, the training error will be lower than the validation.\n",
    "  * Overfitting isn't always a bad thing, as long as your validation loss is going down.\n",
    "  \n",
    "* Question 4: Setting `p` is probabilty of deleting activations, not of keeping activations?\n",
    "* Answer 4: Yes\n",
    "\n",
    "* Question 5: Why does the average activation matter?\n",
    "* Answer 5: If you deleted activations, it will have a knock on effect to later calculations. Your goal is to delete activations, without changing the meaning of future activations.\n",
    "\n",
    "* Question 6: Why are you using a linear activation for an earlier activation?\n",
    "* Answer 6: It's the only choice you have based on what previous layers return.\n",
    "\n",
    "* Question 7: Can you have different dropout by layer?\n",
    "* Answer 7: Pass in array to `ps` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (1): Dropout(p=0.25)\n",
       "  (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (5): Dropout(p=0.125)\n",
       "  (6): Linear(in_features=512, out_features=120, bias=True)\n",
       "  (7): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_learner.ConvLearner.pretrained(arch, data, ps=[0.25, 0.125], precompute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * J doesn't have good intuition for when to use different values off Dropout on final layers.\n",
    "\n",
    "* Question 8: Why measure the loss, instead of accuracy going up?\n",
    "* Answer 8: Because loss is actually being used by SGD so it's good to see it.\n",
    "\n",
    "* Question 9: Does Dropout impact the learning rate?\n",
    "* Answer 9: In theory, but not much in practise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00:25:04 - Structure data problem (Rossman Kaggle competition)\n",
    "\n",
    "* Main dataset provides the following info: at a particular store, how much did they sell?\n",
    "* See [this](lesson4-rossman-data-preprocessing.ipynb) notebook for data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00:26:58 - Preparing features\n",
    "\n",
    "* Winner from the competition came up with useful columns.\n",
    "* List of things we're going to treat as \"categorial variables\"\n",
    "  * Could treat year, month and day as continous, but categorical usually works better in practise.\n",
    "* If it's categorical in the data, you'll have to treat it the same in the model. If continuous, you get to pick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/rossman/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'StateHoliday', 'CompetitionMonthsOpen', 'Promo2Weeks', 'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear', 'State', 'Week', 'Events', 'Promo_fw', 'Promo_bw', 'StateHoliday_fw', 'StateHoliday_bw', 'SchoolHoliday_fw', 'SchoolHoliday_bw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "contin_vars = [\n",
    "    'CompetitionDistance', 'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC',\n",
    "    'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', 'Max_Wind_SpeedKm_h',\n",
    "    'Mean_Wind_SpeedKm_h', 'CloudCover', 'trend', 'trend_DE',\n",
    "    'AfterStateHoliday', 'BeforeStateHoliday', 'Promo', 'SchoolHoliday'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = pd.read_feather(f'{PATH}joined')\n",
    "joined_test = pd.read_feather(f'{PATH}joined_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cardinality refers to number of items in a category: \"cardinality of days of week is 7\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00:30:59 - Audience questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q1: Heuristic for when to bin continuous variables?\n",
    "* A1: Jeremy doesn't bin continuous variables (process of putting continuous data into categorical \"bins\"), though apparently it may be useful in certain cases.\n",
    "\n",
    "* Q2: If you're using year as a category, what happens if it's never seen that year?\n",
    "* A2: It'll be treated as an \"unknown\" year: unknown then just becomes another category.\n",
    "\n",
    "* Q3: If our training dataset doesn't have a category, and test has unknown, how does it work?\n",
    "* A3: It'll probably have learned a way to predict unknowns or will just have a random vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00:33:17 - Preparing features cont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can see we have 844k rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844338"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(joined); n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert to category using Pandas:\n",
    "  * Note that PyTorch expects a float32, which is why the continuous variables are being converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in cat_vars: joined[v] = joined[v].astype('category').cat.as_ordered()\n",
    "for v in contin_vars: joined[v] = joined[v].astype('float32')\n",
    "    \n",
    "dep = 'Sales'\n",
    "\n",
    "joined = joined[cat_vars + contin_vars + [dep, 'Date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run on a sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = dataset.get_cv_idxs(n, val_pct=150000/n)\n",
    "joined_samp = joined.iloc[idxs].set_index('Date')\n",
    "samp_size = len(joined_samp); samp_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Date has some booleans, some integers and some letters that Pandas displays as strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>CompetitionMonthsOpen</th>\n",
       "      <th>Promo2Weeks</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>...</th>\n",
       "      <th>Max_Wind_SpeedKm_h</th>\n",
       "      <th>Mean_Wind_SpeedKm_h</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>trend</th>\n",
       "      <th>trend_DE</th>\n",
       "      <th>AfterStateHoliday</th>\n",
       "      <th>BeforeStateHoliday</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-06-16</th>\n",
       "      <td>257</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-30</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Store DayOfWeek  Year Month Day StateHoliday CompetitionMonthsOpen  \\\n",
       "Date                                                                            \n",
       "2015-06-16   257         2  2015     6  16        False                    24   \n",
       "2013-10-30     4         3  2013    10  30        False                    24   \n",
       "\n",
       "           Promo2Weeks StoreType Assortment  ...  Max_Wind_SpeedKm_h  \\\n",
       "Date                                         ...                       \n",
       "2015-06-16           0         a          a  ...                18.0   \n",
       "2013-10-30           0         c          c  ...                29.0   \n",
       "\n",
       "           Mean_Wind_SpeedKm_h CloudCover trend trend_DE AfterStateHoliday  \\\n",
       "Date                                                                         \n",
       "2015-06-16                 8.0        6.0  63.0     71.0              22.0   \n",
       "2013-10-30                16.0        2.0  74.0     66.0              27.0   \n",
       "\n",
       "           BeforeStateHoliday Promo SchoolHoliday Sales  \n",
       "Date                                                     \n",
       "2015-06-16                0.0   1.0           0.0  5934  \n",
       "2013-10-30              -56.0   0.0           0.0  7800  \n",
       "\n",
       "[2 rows x 39 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_samp.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fast.ai library includes a function called `proc_df`:\n",
    "  * pulls out dependent variables (in this example `Sales`).\n",
    "  * Scales dataset to between -1 and 1 by subtracting the mean and dividing by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y, nas, mapper = structured.proc_df(joined_samp, 'Sales', do_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Also returns a special object which includes the mean and std for subtracting and dividing the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrameMapper(default=False, df_out=False,\n",
       "        features=[(['CompetitionDistance'], StandardScaler(copy=True, with_mean=True, with_std=True)), (['Max_TemperatureC'], StandardScaler(copy=True, with_mean=True, with_std=True)), (['Mean_TemperatureC'], StandardScaler(copy=True, with_mean=True, with_std=True)), (['Min_TemperatureC'], StandardScaler(co...rue, with_std=True)), (['CloudCover_na'], StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "        input_df=False, sparse=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Also handles missing values by setting them to 0 for categorical, or replacing with median variable for continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CompetitionDistance': 2320.0, 'CloudCover': 6.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>CompetitionMonthsOpen</th>\n",
       "      <th>Promo2Weeks</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean_Wind_SpeedKm_h</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>trend</th>\n",
       "      <th>trend_DE</th>\n",
       "      <th>AfterStateHoliday</th>\n",
       "      <th>BeforeStateHoliday</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>CompetitionDistance_na</th>\n",
       "      <th>CloudCover_na</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-06-16</th>\n",
       "      <td>257</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.651394</td>\n",
       "      <td>0.266629</td>\n",
       "      <td>-0.194358</td>\n",
       "      <td>0.487305</td>\n",
       "      <td>-0.525077</td>\n",
       "      <td>1.109608</td>\n",
       "      <td>1.115768</td>\n",
       "      <td>-0.489079</td>\n",
       "      <td>-0.050661</td>\n",
       "      <td>-0.294389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-30</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700532</td>\n",
       "      <td>-2.197401</td>\n",
       "      <td>0.769911</td>\n",
       "      <td>-0.026011</td>\n",
       "      <td>-0.363976</td>\n",
       "      <td>-0.602128</td>\n",
       "      <td>-0.896244</td>\n",
       "      <td>-0.489079</td>\n",
       "      <td>-0.050661</td>\n",
       "      <td>-0.294389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Store  DayOfWeek  Year  Month  Day  StateHoliday  \\\n",
       "Date                                                           \n",
       "2015-06-16    257          2     3      6   16             1   \n",
       "2013-10-30      4          3     1     10   30             1   \n",
       "\n",
       "            CompetitionMonthsOpen  Promo2Weeks  StoreType  Assortment  \\\n",
       "Date                                                                    \n",
       "2015-06-16                     25            1          1           1   \n",
       "2013-10-30                     25            1          3           3   \n",
       "\n",
       "                ...        Mean_Wind_SpeedKm_h  CloudCover     trend  \\\n",
       "Date            ...                                                    \n",
       "2015-06-16      ...                  -0.651394    0.266629 -0.194358   \n",
       "2013-10-30      ...                   0.700532   -2.197401  0.769911   \n",
       "\n",
       "            trend_DE  AfterStateHoliday  BeforeStateHoliday     Promo  \\\n",
       "Date                                                                    \n",
       "2015-06-16  0.487305          -0.525077            1.109608  1.115768   \n",
       "2013-10-30 -0.026011          -0.363976           -0.602128 -0.896244   \n",
       "\n",
       "            SchoolHoliday  CompetitionDistance_na  CloudCover_na  \n",
       "Date                                                              \n",
       "2015-06-16      -0.489079               -0.050661      -0.294389  \n",
       "2013-10-30      -0.489079               -0.050661      -0.294389  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00:38:36 - Selecting validation sets with timeseries data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cross-val should not be random with time series data.\n",
    "* Generally use the most recent data for holdout set, like real life.\n",
    "  * Could take the last 25% of rows, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.75\n",
    "train_size = int(samp_size * train_ratio); train_size\n",
    "val_idx = list(range(train_size, len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A better option, for this case, would be to get the same time period as the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = np.flatnonzero(\n",
    "    (df.index<=datetime.datetime(2014,9,17)) & (df.index>=datetime.datetime(2014, 8, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rachel posted an article on creating validations set [here](http://www.fast.ai/2017/11/13/validation-sets/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00:39:35 - Understand metric for evaluating model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kaggle use root mean squared percent error as the evaluation metric for Rossman competition: $\\text{RMSPE }=\\sqrt{\\frac{1}{n} \\sum\\limits_{i=1}^{n}{(\\frac{y_i-\\hat{y}_i}{y_i})}^2}$\n",
    "  * Since we know that $log(\\frac{a}{b})=log(a)-log(b)$:\n",
    "  \n",
    "  ```\n",
    "  >> math.log(10/5)\n",
    "  >> 0.6931471805599453\n",
    "\n",
    "  >> math.log(10) - math.log(5)\n",
    "  >> 0.6931471805599456\n",
    "  ```\n",
    "  * If you take the log of the data, the root mean squared error will actually get you the root mean squared percent error. You can inverse the results with `exp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_y(a): return np.exp(a)\n",
    "\n",
    "def exp_rmspe(y_pred, targ):\n",
    "    targ = inv_y(targ)\n",
    "    pct_var = (targ - inv_y(y_pred)) / targ\n",
    "    return math.sqrt((pct_var ** 2).mean())\n",
    "\n",
    "max_log_y = np.max(y1)\n",
    "y_range = (0, max_log_y * 1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a `ModelData` object using the data frame with `ColumnarModelData.from_data_frame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = column_data.ColumnarModelData.from_data_frame(PATH, val_idx, df, y_log, cat_flds=cat_vars, bs=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * `PATH` - path where you want to store any temp files or models etc.\n",
    "  * `val_idx` - list of rows to put in validation set.\n",
    "  * `df` - DataFrame.\n",
    "  * `yl` - dependent variables.\n",
    "  * `cat_flds` - which fields should be considered categorical?\n",
    "  * `bs` - batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get number of levels of each categorical var:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sz = [\n",
    "    (c, len(joined_samp[c].cat.categories) + 1) for c in cat_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Store', 1116),\n",
       " ('DayOfWeek', 8),\n",
       " ('Year', 4),\n",
       " ('Month', 13),\n",
       " ('Day', 32),\n",
       " ('StateHoliday', 3),\n",
       " ('CompetitionMonthsOpen', 26),\n",
       " ('Promo2Weeks', 27),\n",
       " ('StoreType', 5),\n",
       " ('Assortment', 4),\n",
       " ('PromoInterval', 4),\n",
       " ('CompetitionOpenSinceYear', 24),\n",
       " ('Promo2SinceYear', 9),\n",
       " ('State', 13),\n",
       " ('Week', 53),\n",
       " ('Events', 22),\n",
       " ('Promo_fw', 7),\n",
       " ('Promo_bw', 7),\n",
       " ('StateHoliday_fw', 4),\n",
       " ('StateHoliday_bw', 4),\n",
       " ('SchoolHoliday_fw', 9),\n",
       " ('SchoolHoliday_bw', 9)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_sz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00:45:39 - Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Firstly continuous variables:\n",
    "  * Bunch of floating point numbers in vector, for example one with 20 columns. `(1, 20)`\n",
    "  * Then put through a matrix product with anther matrix with a matching number of rows to the vectors columns: `(20, 100)`\n",
    "  * That returns a vector with 100 columns: `(1, 100)`, which are then put through a relu activation.\n",
    "  * Then put through a relu activations.\n",
    "  * Lasly, put through another matrix multiplication, of `(100, 1)` which returns a single value: `(1, 1)`.\n",
    "* Aside from adding dropout and stuff, there aren't many interesting architectural choices when using fully-connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Categorical:\n",
    "  * For each set of categorical vars (eg day of week): Create another matrix with n columns and a row for each category.\n",
    "    * Called an \"embedding matrix\".\n",
    "  * Then, at training time, pull out the appropriate row and concat to continuous variables.\n",
    "  * Basically, it's a way to convert categorical variables into continuous numbers.\n",
    "  * Side effect of the embedding is that they're sometimes human interpretable and can be quite interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00:55:56 - Audience questions\n",
    "\n",
    "* Q1: Is there a heuristic for selecting the size of embeddings?\n",
    "* A1: Half the cardinality of category (eg `8//2=4)` fields for day of week), as long as it's no greater than 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs = [(c, min(50, (c+1)//2)) for _, c in cat_sz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1116, 50),\n",
       " (8, 4),\n",
       " (4, 2),\n",
       " (13, 7),\n",
       " (32, 16),\n",
       " (3, 2),\n",
       " (26, 13),\n",
       " (27, 14),\n",
       " (5, 3),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (24, 12),\n",
       " (9, 5),\n",
       " (13, 7),\n",
       " (53, 27),\n",
       " (22, 11),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (9, 5),\n",
       " (9, 5)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_szs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q2: Would you always build embedding matrix for each categorical feature?\n",
    "* A2: Yes.\n",
    "\n",
    "* Q3: Besides random initialisation, is there another way to init embedding?\n",
    "* A3: You could either use random, or find another pretrained embedding matrix. Perhaps one has been trained to predict similar products.\n",
    "\n",
    "* Q4: Why not just use a one-hot encoded values instead of embedding?\n",
    "* A4: You could just pass in 7 vars, 6 of them 0 and 1 of them 1. Problem: concept of Sunday, could only be associated with a single floating point number. With embeddings, it becomes a concept in 4 dimensional space, which can give them \"rich semantic concepts\".\n",
    "  * Examples:\n",
    "    * weekends may have a different behaviour, causing some number to be higher.\n",
    "    * one column may represent certain products selling better on certain days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01:07:14 - Dealing with dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fast.ai function called `add_datepart` that takes a dataframe and a datefield column name.\n",
    "  * It then removes the date and replaces it with categorical variables about the date: day of week, is it end of quarter, start of month etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = pd.DataFrame({'Date': [datetime.datetime(2017, 3, 1), datetime.datetime(2017, 3, 2)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-03-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date\n",
       "0 2017-03-01\n",
       "1 2017-03-02"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured.add_datepart(date_df, 'Date', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dayofweek</th>\n",
       "      <th>Dayofyear</th>\n",
       "      <th>Is_month_end</th>\n",
       "      <th>Is_month_start</th>\n",
       "      <th>Is_quarter_end</th>\n",
       "      <th>Is_quarter_start</th>\n",
       "      <th>Is_year_end</th>\n",
       "      <th>Is_year_start</th>\n",
       "      <th>Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1488326400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-03-02</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1488412800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Year  Month  Week  Day  Dayofweek  Dayofyear  Is_month_end  \\\n",
       "0 2017-03-01  2017      3     9    1          2         60         False   \n",
       "1 2017-03-02  2017      3     9    2          3         61         False   \n",
       "\n",
       "   Is_month_start  Is_quarter_end  Is_quarter_start  Is_year_end  \\\n",
       "0            True           False             False        False   \n",
       "1           False           False             False        False   \n",
       "\n",
       "   Is_year_start     Elapsed  \n",
       "0          False  1488326400  \n",
       "1          False  1488412800  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01:10:05 - Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = md.get_learner(\n",
    "    emb_szs=emb_szs,\n",
    "    n_cont=len(df.columns)-len(cat_vars),\n",
    "    emb_drop=0.04,\n",
    "    out_sz=1,\n",
    "    szs=[1000, 500],\n",
    "    drops=[0.001, 0.01],\n",
    "    y_range=y_range\n",
    ")\n",
    "\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * `emb_szs` - embedding matrix sizes.\n",
    "  * `n_cont` - number of continous variables.\n",
    "  * `emb_drop` - how much dropout to use.\n",
    "  * `out_sz` - output size.\n",
    "  * `szs` - how many activations to use.\n",
    "  * `drops` - how much dropout to use in the later layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1116, 50),\n",
       " (8, 4),\n",
       " (4, 2),\n",
       " (13, 7),\n",
       " (32, 16),\n",
       " (3, 2),\n",
       " (26, 13),\n",
       " (27, 14),\n",
       " (5, 3),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (24, 12),\n",
       " (9, 5),\n",
       " (13, 7),\n",
       " (53, 27),\n",
       " (22, 11),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (9, 5),\n",
       " (9, 5)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_szs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can now do the standard stuff, like getting the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583065d4b19e48959b41dbadadbae314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 735/1120 [00:50<00:26, 14.70it/s, loss=0.329] "
     ]
    }
   ],
   "source": [
    "m.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m.sched.plot(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that we're passing in metrics to be printed at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f55e91dc4c4ea6b512e681f3b9dcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   exp_rmspe                      \n",
      "    0      0.026518   0.022992   0.159085  \n",
      "    1      0.018788   0.029464   0.152526                       \n",
      "    2      0.017182   0.021571   0.13363                        \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.021571023, 0.13362987312569344]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(lr, 3, metrics=[exp_rmspe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0403c76e40894f85b0e567ebdc612080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   exp_rmspe                      \n",
      "    0      0.012154   0.01711    0.121186  \n",
      "    1      0.011085   0.018633   0.12522                        \n",
      "    2      0.010783   0.01749    0.121782                       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.017490305, 0.1217821107997797]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(lr, 3, metrics=[exp_rmspe], cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The winners of the Kaggle competition did a lot more feature engineering. Generally deep learning approaches require somewhat less feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01:15:02 - Audience questions\n",
    "\n",
    "* Q1: Are we using time series in any of the fits?\n",
    "* A1: Yes, by converting the date data into categorical variables.\n",
    "\n",
    "* Q2: In the earlier CNNs we didn't pass data during the fit. Is that the case here?\n",
    "* A2: We aren't passing in anything at fit time. The model that we build depends on the data, hence the learner being returned from the data: `m.get_learner`.\n",
    "\n",
    "* Q3: Do I just need to figure out what to put into categorical variables / embeddings on my own dataset?\n",
    "* A3: Steps for your own dataset:\n",
    "  1. Put your data in a Pandas dataframe and list the categorical variables and continuous variables.\n",
    "  2. Figure out which rows go in the validation dataset.\n",
    "  3. Call `ColumnarModelData.from_data_frame(PATH, val_idx, df, yl, cat_flds=cat_vars, bs=128`, passing in your data.\n",
    "  4. Create your list of how big your embedding matrices should be.\n",
    "  5. Call  `get_learner` to get your learner.\n",
    "  6. Call `fit` to fit the data.\n",
    "  \n",
    "* Q4: How can data augmentation be used here?\n",
    "* A4: Data augmentation doesn't really exist with structured data yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01:23:34 - Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NLP is the most up-and-coming area of Deep Learning, about 2-3 years behind image classification.\n",
    "* Language modelling:\n",
    "  * build a model where given a few words of a sentence, can you predict the next word?\n",
    "  * [Swiftkey](https://swiftkey.com/en) used DL for it.\n",
    "* Language models can be used in classification tasks (like sentiment analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  01:31:35 - Audience questions\n",
    "\n",
    "* Q1: Why not just learn the classification model without a language model?\n",
    "* A1: We already know that transfer learning is useful. Also, the IMDB reviews are sometimes quite large and it's too much to try to learn English *and* how to predict sentiment.\n",
    "\n",
    "* Q2: Is this similar to the [char-rnn](https://github.com/karpathy/char-rnn)?\n",
    "* A2: Yes, except language models usually work at a word level, rather than a character level: they tend to be more powerful.\n",
    "\n",
    "* Q3: To what extent are these generated words and sentences seen before or randomly created?\n",
    "* A3: All the words must have been seen before. The sentences generated would be similar but not exact to what's generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01:36:37 - New imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Torchtext](https://github.com/pytorch/text) - Pytorch's NLP library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Some new text-specific fast.ai stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.fastai.rnn_reg import *\n",
    "from fastai.fastai.rnn_train import *\n",
    "from fastai.fastai.nlp import *\n",
    "from fastai.fastai.lm_rnn import *\n",
    "\n",
    "import dill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Going to be working with [IMDB large movie review dataset](http://ai.stanford.edu/~amaas/data/sentiment/).\n",
    "  * Very well studied in academia.\n",
    "  * 50k reviews.\n",
    "* Going to start by creating a language model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/aclImdb/'\n",
    "\n",
    "TRN_PATH = 'train/all/'\n",
    "VAL_PATH = 'test/all/'\n",
    "\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-04-20 04:56:49--  http://files.fast.ai/data/aclImdb.tgz\n",
      "Resolving files.fast.ai (files.fast.ai)... 67.205.15.147\n",
      "Connecting to files.fast.ai (files.fast.ai)|67.205.15.147|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 145982645 (139M) [text/plain]\n",
      "Saving to: ‘data/aclImdb.tgz’\n",
      "\n",
      "aclImdb.tgz         100%[===================>] 139.22M  11.9MB/s    in 21s     \n",
      "\n",
      "2018-04-20 04:57:11 (6.61 MB/s) - ‘data/aclImdb.tgz’ saved [145982645/145982645]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://files.fast.ai/data/aclImdb.tgz --directory-prefix=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf data/aclImdb.tgz -C data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01:37:54 - Analysing IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdbEr.txt  imdb.vocab\tREADME\ttest  train\r\n"
     ]
    }
   ],
   "source": [
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Look inside training folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_0.txt',\n",
       " '0_3.txt',\n",
       " '0_9.txt',\n",
       " '10000_0.txt',\n",
       " '10000_4.txt',\n",
       " '10000_8.txt',\n",
       " '1000_0.txt',\n",
       " '10001_0.txt',\n",
       " '10001_10.txt',\n",
       " '10001_4.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_files = !ls {TRN}\n",
    "trn_files[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Example review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Everybody has seen 'Back To The Future,' right? Whether you LIKE that movie or not, you've seen an example of how to make a time-travel movie work. A torn-up poster for 'Back To The Future' shows up in this movie, representing, perhaps unintentionally, what the makers of 'Tangents' (aka 'Time Chasers') did to the time-travel formula. Then again, the movie claims to have been made in 1994, but it looks -- and sounds -- like it was produced at least ten years earlier, so maybe they achieved time-travel after all.<br /><br />Start with an intensely unappealing leading man. I mean, what woman doesn't love gangly, whiny, lantern-jawed, butt-chinned, mullet-men with Coke-bottle glasses? Oh, none of you? Prepare to tough it out, ladies, cuz that's what this movie gives you.<br /><br />Second, add a leading lady who -- while not entirely unattractive -- represents many '80s clichés: big hair, too much makeup, two different plaids, shoulder pads, acid-washed mom-jeans, etc.<br /><br />Throw in a Michael Medved look-alike who wears pink blazers with white pants, a stunningly transparent villain who talks like Mortimer Snerd and has an office that looks like a circus-themed library, and evil henchmen who have nothing better to do than direct air traffic. That's our cast, folks. Enjoy!<br /><br />I could try to explain the plot, but it will take a lot less time for you to just track down a copy of this movie and watch it yourself. If YOU figure out the plot, please don't hesitate to share it with me.<br /><br />I would strongly advise watching this movie with the help of the folks at Mystery Science Theater 3000. I don't think it could stand on its own.<br /><br />The film, 'Tangents': 3 stars -- at least they tried.<br /><br />MST3K's 'Time Chasers' episode: 8 stars -- they actually succeeded.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = !cat {TRN}{trn_files[7]}\n",
    "review[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check how many words in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17486581\r\n"
     ]
    }
   ],
   "source": [
    "!find {TRN} -name '*.txt' | xargs cat | wc -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5686719\r\n"
     ]
    }
   ],
   "source": [
    "!find {VAL} -name '*.txt' | xargs cat | wc -w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Need to convert text into a list of numbers, first step is to convert into a list of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 37.4MB 81.8MB/s ta 0:00:0110% |▏                               | 174kB 438kB/s eta 0:01:25    58% |██████████████████▊             | 21.9MB 3.1MB/s eta 0:00:06\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "  Running setup.py install for en-core-web-sm ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed en-core-web-sm-2.0.0\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/en_core_web_sm\n",
      "    -->\n",
      "    /home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tok = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Everybody, has, seen, ', Back, To, The, Future, ,, ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in spacy_tok(review[0])][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With Torchtext, need to create a \"field\". \n",
    "  * Field is a definition of how to process text.\n",
    "  * In this example, we're telling it to tokenise everything and convert to lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize='spacy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Need to use `dill` to dump the TEXT object, since it doesn't work with Pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data/aclImdb/models’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir {PATH}models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(TEXT, open(f'{PATH}models/TEXT.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = dill.load(open(f'{PATH}models/TEXT.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can now create a `ModelData` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64; bptt=70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * `PATH` - standard path.\n",
    "  * `TEXT` - torchtext field definition.\n",
    "  * `**FILES` - location of training and validation files.\n",
    "  * `min_freq=10` - any word that occur less than 10 times, ignore.\n",
    "  * `bptt` - stands for \"back prop through time\": how long are the sentences we'll put on the GPU at a time.\n",
    "* Model words as follows:\n",
    "  * Fills the `TEXT` object with a `vocab` attribute.\n",
    "     * Vocab refers to unique words found in text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Print # batches; # unique tokens; # tokens in the training set; # sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4583, 37392, 1, 20540756)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Map integer IDs to unique tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is', 'in', 'it']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert words to ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In `LanguageModelData` there is only one item for each dataset, which is all words of text joined together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['picking',\n",
       " 'up',\n",
       " 'the',\n",
       " 'jacket',\n",
       " 'of',\n",
       " 'this',\n",
       " 'dvd',\n",
       " 'in',\n",
       " 'the',\n",
       " 'video',\n",
       " 'store',\n",
       " 'i']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.trn_ds[0].text[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `torchtext` handles turning words into integer automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3701\n",
       "   68\n",
       "    2\n",
       " 5641\n",
       "    7\n",
       "   13\n",
       "  300\n",
       "   10\n",
       "    2\n",
       "  392\n",
       " 1089\n",
       "   12\n",
       "[torch.LongTensor of size 12x1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.numericalize([md.trn_ds[0].text[:12]], device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'admit'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[1003]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01:45:47 - Audience questions\n",
    "\n",
    "* Q1: Common to do stemming or [lemmatising](https://en.wikipedia.org/wiki/Lemmatisation)?\n",
    "* A1: Not really - usually best to leave it alone as much as possible.\n",
    "\n",
    "* Q2: Is context important?\n",
    "* A2: Context is very important. Hence why the words are ordered: this isn't bag-of-words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01:47:52 - Batching\n",
    "\n",
    "1. Start with the full corpus of reviews concatenated.\n",
    "2. Break the words into n sections.\n",
    "3. Create matrix, where each column is one of these sections.\n",
    "4. Row each batch, take something like 70 rows, so you have a matrix that's (70, 64). Which would give you 64 different document fragments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `LanguageModelData` object create batches with 64 columns (batch size) and varying sequence lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "   3701    297      9  ...    1667     12     14\n",
       "     68  13351    359  ...      43    173     33\n",
       "      2     51     24  ...     472      6    324\n",
       "         ...            ⋱           ...         \n",
       "      7     91    157  ...       3      6     83\n",
       "     13   1001     56  ...     500   1943    867\n",
       "     25     52      7  ...      13      7     54\n",
       " [torch.cuda.LongTensor of size 69x64 (GPU 0)], Variable containing:\n",
       "     68\n",
       "  13351\n",
       "    359\n",
       "   ⋮   \n",
       "   1659\n",
       "   1310\n",
       "     13\n",
       " [torch.cuda.LongTensor of size 4416 (GPU 0)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(md.trn_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Note that the size is not exactly 70 row (in that example it's `69` rows). Torchtext randomly changes the row size when doing bptt.\n",
    " * Couple of examples of the data in the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(md.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picking up the jacket of this dvd in the video store i was intrigued . having watched this sorry excuse for a western i think director dwight should give a medal for the guy who designed the jacket and has lured to their doom other unsuspecting viewers . the script of the film is potentially interesting ... and i bet that 's what the impressive members of this film 's\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(TEXT.vocab.itos[int(w)] for w in batch[0][:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plays psychos or really bad people . it 's funny that this would later lead him play a true loon like in \" 12 monkeys \" and that he would be on the other end of the spectrum in david fincher 's \" seven \" . <eos> when elvis filmed ' speedway ' in june of 1967 it was a time of change . he had been married just over\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(TEXT.vocab.itos[int(w)] for w in batch[0][:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01:55:50 - Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Want to create an embedding matrix with 200 cols with a row for each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz = 200 # size of each embedding vector\n",
    "nh = 500    # number of hidden activations per layer\n",
    "nl = 3      # number of layers\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Large amounts of *Momentum* don't work that well, so we create a version of Adam will less momentum (default is 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create the learner:\n",
    "  * Fast.ai uses state of the art [AWD LSTM Language Model](https://github.com/salesforce/awd-lstm-lm) by Stephen Merity, which uses lots of Dropout. No known ways to find best dropout - need to experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = md.get_model(\n",
    "    opt_fn, em_sz, nh, nl, dropouti=0.05, dropout=0.05,\n",
    "    wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note the multiple dropout arguments (details available in the last lecture).\n",
    "  * If you are overfitting, increase all dropout params, decrease if underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clip the weights to ensure weights don't explode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.clip = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529de5668faa4d41b21a4b33aa6dabb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                 \n",
      "    0      4.825006   4.709303  \n",
      "    1      4.649139   4.522534                                \n",
      "    2      4.53842    4.440321                                \n",
      "    3      4.592644   4.470359                                \n",
      "    4      4.513704   4.394659                                \n",
      " 77%|███████▋  | 3551/4583 [16:28<04:47,  3.59it/s, loss=4.45]"
     ]
    }
   ],
   "source": [
    "learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02:02:28 - Audience questions\n",
    "\n",
    "* Q1: How does this compare to using Word2Vec or Glove?\n",
    "* A1: This technique appears to be more powerful.\n",
    "\n",
    "* Q2: What is the model architecture used?\n",
    "* A2: A RNN using an LSTM (long short term memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('adam1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_encoder('adam1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2173642e79904e82bafd88603e317fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      4.470424   4.371257  \n",
      "    1      4.467573   4.365174                                \n",
      "    2      4.448483   4.341675                                \n",
      "    3      4.424094   4.320922                                \n",
      " 49%|████▉     | 2251/4583 [10:21<10:44,  3.62it/s, loss=4.41]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5      4.375303   4.275402                                \n",
      "    6      4.351441   4.255511                                \n",
      "    7      4.304695   4.238498                                \n",
      "    8      4.278119   4.230899                                \n",
      "    9      4.290093   4.229005                                \n",
      " 92%|█████████▏| 4214/4583 [19:30<01:42,  3.60it/s, loss=4.46]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 3566/4583 [16:30<04:42,  3.60it/s, loss=4.45]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 3012/4583 [13:56<07:16,  3.60it/s, loss=4.44]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2440/4583 [11:18<09:56,  3.59it/s, loss=4.42]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41%|████      | 1878/4583 [08:41<12:31,  3.60it/s, loss=4.39]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    14     4.364251   4.277149                                \n",
      " 28%|██▊       | 1292/4583 [05:58<15:12,  3.61it/s, loss=4.36]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    15     4.341483   4.257161                                \n",
      " 16%|█▌        | 714/4583 [03:18<17:57,  3.59it/s, loss=4.34]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    16     4.314206   4.237568                                \n",
      "  3%|▎         | 135/4583 [00:37<20:43,  3.58it/s, loss=4.3] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 4121/4583 [19:04<02:08,  3.60it/s, loss=4.27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 3502/4583 [16:12<05:00,  3.60it/s, loss=4.25]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2883/4583 [13:23<07:53,  3.59it/s, loss=4.25]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1929/4583 [08:57<12:19,  3.59it/s, loss=4.45]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    20     4.45407    4.330963                                \n",
      "    21     4.431024   4.325056                                \n",
      "    22     4.41102    4.308909                                \n",
      "    23     4.394272   4.28938                                 \n",
      "    24     4.360949   4.267609                                \n",
      "    25     4.332253   4.245154                                \n",
      "    26     4.302126   4.226168                                \n",
      "    27     4.273302   4.212529                                \n",
      "    28     4.249753   4.205445                                \n",
      "    29     4.238341   4.203876                                \n",
      "    30     4.435757   4.320856                                \n",
      "    31     4.427365   4.311517                                \n",
      "    32     4.399558   4.299383                                \n",
      "    33     4.376254   4.277548                                \n",
      "    34     4.349744   4.259276                                \n",
      "    35     4.314749   4.236638                                \n",
      "    36     4.283758   4.218967                                \n",
      "    37     4.27303    4.206128                                \n",
      "    38     4.242893   4.198182                                \n",
      "    39     4.247306   4.196779                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([4.19678])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 4, wds=1e-6, cycle_len=10, cycle_save_name='adam3_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('adam1_10_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595f5ac5bff04f0da9b1097ac11409c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      4.244789   4.198284  \n",
      "    1      4.427986   4.316352                                \n",
      "    2      4.411712   4.310209                                \n",
      "    3      4.406754   4.305369                                \n",
      "    4      4.404938   4.297316                                \n",
      "    5      4.386481   4.287112                                \n",
      "    6      4.386738   4.280646                                \n",
      "    7      4.374347   4.271933                                \n",
      "    8      4.352447   4.256832                                \n",
      "    9      4.344912   4.248394                                \n",
      "    10     4.321443   4.236432                                \n",
      "    11     4.312613   4.225651                                \n",
      "    12     4.280505   4.215626                                \n",
      "    13     4.282414   4.206636                                \n",
      "    14     4.25259    4.198179                                \n",
      "    15     4.235448   4.192406                                \n",
      "    16     4.239449   4.188233                                \n",
      "    17     4.216629   4.184596                                \n",
      "    18     4.213963   4.183657                                \n",
      "    19     4.206912   4.183356                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([4.18336])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 1, wds=1e-6, cycle_len=20, cycle_save_name='adam3_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('adam1_20_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_encoder('adam1_20_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7e0593b82a49a38edbc7ae048e7c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      4.402206   4.306556  \n",
      "    1      4.399321   4.296581                                \n",
      "    2      4.396214   4.284479                                \n",
      "    3      4.35387    4.26331                                 \n",
      "    4      4.328579   4.244382                                \n",
      "    5      4.30673    4.223781                                \n",
      "    6      4.279538   4.206563                                \n",
      "    7      4.263763   4.193859                                \n",
      "    8      4.242565   4.18583                                 \n",
      "    9      4.21544    4.184016                                \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([4.18402])]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 1, wds=1e-6, cycle_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('adam3_10_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_encoder('adam3_10_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02:04:53 - Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\". So , it was n't quite was I was expecting , but I really liked it anyway ! The best\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=learner.model\n",
    "ss=\"\"\". So, it wasn't quite was I was expecting, but I really liked it anyway! The best\"\"\"\n",
    "s = [[i.text for i in spacy_tok(ss)]]\n",
    "t=TEXT.numericalize(s)\n",
    "' '.join(s[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Manual steps to test language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size o 1\n",
    "m[0].bs = 1\n",
    "\n",
    "# Turn off Dropout\n",
    "m.eval()\n",
    "\n",
    "# Reset hidden state\n",
    "m.reset()\n",
    "\n",
    "# Get predictions from model\n",
    "res, *_ = m(t)\n",
    "\n",
    "# Put batch size batch to what it was\n",
    "m[0].bs=bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* See top 10 predictions for next word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thing',\n",
       " 'was',\n",
       " 'movie',\n",
       " 'of',\n",
       " ',',\n",
       " 'film',\n",
       " 'is',\n",
       " 'performance',\n",
       " 'scene',\n",
       " '<unk>']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nexts = torch.topk(res[-1], 10)[1]\n",
    "[TEXT.vocab.itos[o] for o in to_np(nexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". So, it wasn't quite was I was expecting, but I really liked it anyway! The best \n",
      "\n",
      "thing , and the film is a bit of a disappointment . the film is a bit of a disappointment , but it 's a good film . <eos> i have to say that i am a huge fan of the original series . i have seen the original , ...\n"
     ]
    }
   ],
   "source": [
    "print(ss,\"\\n\")\n",
    "for i in range(50):\n",
    "    n = res[-1].topk(2)[1]\n",
    "    n = n[1] if n.data[0] == 0 else n[0]\n",
    "    print(TEXT.vocab.itos[n.data[0]], end=' ')\n",
    "    res,*_ = m(n[0].unsqueeze(0))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02:05:10 - Use pretrained language model for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sentiment model must use the same `vocab` as language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = pickle.load(open(f'{PATH}models/TEXT.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB_LABEL = data.Field(sequential=False)\n",
    "splits = torchtext.datasets.IMDB.splits(TEXT, IMDB_LABEL, 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = splits[0].examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pos',\n",
       " 'this modern film noir with its off beat humour and dizzying succession of plot twists delivers')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.label, ' '.join(t.text[:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fast.ai can create a `ModelData` object straight from `torchtext` splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "md2 = TextData.from_splits(PATH, splits, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = md2.get_model(opt_fn, 1500, bptt, emb_sz=em_sz, n_hid=nh, n_layers=nl, \n",
    "           dropout=0.1, dropouti=0.4, wdrop=0.5, dropoute=0.05, dropouth=0.3)\n",
    "m3.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "m3.load_encoder(f'adam3_10_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Increase the max gradient clipping to get SGDR to perform better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.clip = 25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use differential learning rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Want to freeze all but the last layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0ffe4116a24138bc1ce19014e55beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.671642   0.397493   0.833486  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.39749]), 0.8334862434097735]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.freeze_to(-1)\n",
    "m3.fit(lrs/2, 1, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can then unfreeze layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db811b192604dafbd65eeea2b6d7ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.497285   0.291096   0.882659  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.2911]), 0.8826590023739705]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.unfreeze()\n",
    "m3.fit(lrs, 1, metrics=[accuracy], cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5366b6eb7a28499894f8d695bad22c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.408477   0.269311   0.902395  \n",
      "    1      0.392739   0.248186   0.905367                    \n",
      "    2      0.365437   0.258713   0.906903                    \n",
      "    3      0.354326   0.25865    0.905984                    \n",
      "    4      0.342144   0.271602   0.910488                    \n",
      "    5      0.336043   0.252554   0.911087                    \n",
      "    6      0.317494   0.248025   0.916649                    \n",
      "    7      0.318077   0.246904   0.917465                    \n",
      "    8      0.312234   0.225775   0.920106                    \n",
      "    9      0.290931   0.243646   0.917602                    \n",
      "    10     0.277402   0.283826   0.917648                    \n",
      "    11     0.272603   0.248851   0.920308                    \n",
      "    12     0.29203    0.260669   0.919272                    \n",
      "    13     0.272543   0.266593   0.919176                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.26659]), 0.9191755028207785]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.fit(lrs, 7, metrics=[accuracy], cycle_len=2, cycle_save_name='imdb2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50016c1bcd2407ab86e023f3cf7b5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    }
   ],
   "source": [
    "m3.fit(lrs, 1, metrics=[accuracy], cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.save('split_model_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.load('split_model_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02:08:00 - Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92404"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_np(*m3.predict_with_targs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Jeremy manages to receive 94.5%, which is better than the state of the art according the Bradbury et al paper, [Learned in translation: contextualized word vectors](https://einstein.ai/research/learned-in-translation-contextualized-word-vectors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02:11:39 -  Intro to collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Very little new to learn: most things have already been covered in earlier parts of the course.\n",
    "* See Lesson 5 notebook for walkthrough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
