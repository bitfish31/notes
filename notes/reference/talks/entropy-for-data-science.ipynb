{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy for Data Science\n",
    "\n",
    "Notes from [Introduction to Entropy for Data Science](https://www.youtube.com/watch?v=IPkRVpXtbdY).\n",
    "\n",
    "* Concept borrowed from physics.\n",
    "* Always a calculation of a vector of categorical variables.\n",
    "* Formula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Entropy} (E(\\overrightarrow{d}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$E(\\overrightarrow{d}) = -\\sum\\limits_{i=1}^{k} p_i \\log_2(p_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sum across the probability of some class occuring. Eg if it is gender and there are 60/100 male recorded, the probability would be (60/100)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``-( (60/100) * log2(60/100) + (40/100) * log2(40/100) ) = 0.9709505944546686``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So, a series where it's very hard to predict what you will get if you took an object at random would be high, and if easy, low.\n",
    "* If it was mostly woman at some event, let's say 95% of the participants were woman, the entropy would be low:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28639695711595625"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woman_prob = 95/100\n",
    "man_prob = 5/100\n",
    "\n",
    "-(woman_prob * log2(woman_prob) + man_prob * log2(man_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: you take the negative to inverse the negative result returned from the log:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.014499569695115089"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log2(99/100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas, if it was a 50/50 split, the entropy would be high: your predictions are uncertain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woman_prob = 50/100\n",
    "man_prob = 50/100\n",
    "\n",
    "-(woman_prob * log2(woman_prob) + man_prob * log2(man_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
